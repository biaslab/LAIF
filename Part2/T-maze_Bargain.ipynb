{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-Maze with Opponent Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `c:\\Simulations\\LAIF`\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\"..\")\n",
    "Pkg.instantiate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using RxInfer, LinearAlgebra, Plots\n",
    "\n",
    "include(\"helpers.jl\")\n",
    "include(\"../goal_observation.jl\")\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation parameters\n",
    "αs = [0.8, 0.85, 0.9, 0.95, 1.0] # Possible offers\n",
    "L = length(αs)\n",
    "c = 2.0\n",
    "S = 30\n",
    "seed = 666\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primary Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function t_maze_primary(A, D, x)\n",
    "    u = datavar(Matrix{Int64}, 2) # Policy for evaluations\n",
    "    z = randomvar(2) # Latent states\n",
    "    c = datavar(Vector{Float64}, 2) # Goal prior statistics\n",
    "\n",
    "    z_0 ~ Categorical(D) # State prior\n",
    "\n",
    "    z_k_min = z_0\n",
    "    for k=1:2\n",
    "        z[k] ~ Transition(z_k_min, u[k])\n",
    "        c[k] ~ GoalObservation(z[k], A) where { # Observation matrix depends on offer by secondary agent\n",
    "            meta=GeneralizedMeta(x[k]), \n",
    "            pipeline=GeneralizedPipeline(vague(Categorical,16))}\n",
    "\n",
    "        z_k_min = z[k] # Reset for next slice\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"primary_agent.jl\")\n",
    "include(\"primary_environment.jl\") # Environment for primary agent\n",
    "\n",
    "(B, C, D) = constructPrimaryBCD(c)\n",
    "\n",
    "rs = generateGoalSequence(seed, S) # Sets random seed and returns reproducible goal sequence\n",
    "(reset, execute, observe) = initializePrimaryWorld(B, rs) # Define interation (Markov blanket) with the T-maze environment\n",
    "(infer, act) = initializePrimaryAgent(B, C, D)\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Secondary Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model function t_maze_secondary(B_s, x, u)\n",
    "    c = datavar(Vector{Float64})\n",
    "\n",
    "    B ~ MatrixDirichlet(B_s)\n",
    "    c ~ GoalObservation(u, B) where {\n",
    "            meta=GeneralizedMeta(x),\n",
    "            pipeline=GeneralizedPipeline()}\n",
    "end\n",
    "\n",
    "@constraints function structured(approximate::Bool)\n",
    "    if approximate\n",
    "        q(B) :: SampleList(20)\n",
    "    end\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"secondary_agent.jl\")\n",
    "include(\"secondary_environment.jl\") # Environment for secondary agent represents an interaction with the primary agent\n",
    "\n",
    "B_0 = constructSecondaryPriors()\n",
    "\n",
    "(execute_prime, observe_prime) = initializeSecondaryWorld() # Defines interaction (Markov blanket) with primary agent\n",
    "(infer_prime, act_prime) = initializeSecondaryAgent(B_0)\n",
    "\n",
    "# Step through the experimental protocol\n",
    "Bs = Vector{Matrix}(undef, S) # Posterior statistics for A\n",
    "Gs = Vector{Vector}(undef, S) # Free energy values\n",
    "as = Vector{Union{Int64, Missing}}(missing, S) # Actions per time\n",
    "os = Vector{Union{Vector, Missing}}(missing, S) # Observations (one-hot) per time\n",
    "for s = 1:S\n",
    "    # Make offer at t=1\n",
    "    (Gs[s], _) = infer_prime(1, as[s], os[s])\n",
    "         as[s] = act_prime(Gs[s])\n",
    "                 execute_prime(s, as[s]) # Triggers inference in primary agent\n",
    "         os[s] = observe_prime() # Observes cue-visit of primary agent\n",
    "    \n",
    "    # Learn at t=2        \n",
    "    (_, Bs[s]) = infer_prime(2, as[s], os[s])\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"c:\\\\Simulations\\\\LAIF\\\\Part2\\\\figures\\\\GFE_offers.png\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "include(\"visualizations.jl\")\n",
    "plotOffers(Gs)\n",
    "savefig(\"figures/GFE_offers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
